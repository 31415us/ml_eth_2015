\documentclass[a4paper, 11pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[pdftex]{hyperref}

% Lengths and indenting
\setlength{\textwidth}{16.5cm}
\setlength{\marginparwidth}{1.5cm}
\setlength{\parindent}{0cm}
\setlength{\parskip}{0.15cm}
\setlength{\textheight}{22cm}
\setlength{\oddsidemargin}{0cm}
\setlength{\evensidemargin}{\oddsidemargin}
\setlength{\topmargin}{0cm}
\setlength{\headheight}{0cm}
\setlength{\headsep}{0cm}

\renewcommand{\familydefault}{\sfdefault}

\title{Machine Learning 2014: Project 2 - Classification Report}
\author{ivankaya@student.ethz.ch\\vlucas@student.ethz.ch\\piusv@student.ethz.ch\\}
\date{\today}

\begin{document}
\maketitle

\section*{Experimental Protocol}
%Suppose that someone wants to reproduce your results. Briefly describe the steps used to obtain the
%predictions starting from the raw data set downloaded from the project website. Use the following
%sections to explain your methodology. Feel free to add graphs or screenshots if you think it's
%necessary. The report should contain a maximum of 2 pages.

\section{Tools}
%Which tools and libraries have you used (e.g. Matlab, Python with scikit-learn, Java with Weka,
%SPSS, language x with library y, $\ldots$). If you have source-code (Matlab scripts, Python scripts, Java source folder, \dots),
%make sure to submit it on the project website together with this report. If you only used
%command-line or GUI-tools describe what you did.

We exclusively used $Matlab$ for this assignment.
We used $csvread$ to read the provided training and validation data sets and $csvwrite$ to write our predictions. We also used $fitctree$ for desicision tree, $fitcdiscr$ for discriminant analysis, $fitcnb$ for multiclass naive Bayes, $fitcecoc$ and $fitcsvm$ for our support vector machine, $fitcknn$ for the KNN classifier and $TreeBagger$ for the random forest. Moreover, the voting process was simply realized using the matlab function $mode$.

\section{Algorithm}
%Describe the algorithm you used for regression (e.g. ordinary least squares, ridge regression, $\ldots$)

We used $3$ binary SVMs with gaussian kernels in a one-vs-one scheme. To train
these binary classifiers we used the $fitcsvm$ function provided by $Matlab$.
To combine the three for the final prediction we used the $fitcecoc$ function.

\section{Features}
%Did you construct any new features? What feature transforms did you use?

We did not construct any additional features since we used SVM with gaussian
kernels.

\section{Parameters}
%How did you find the parameters of your model? (What parameters have you searched over, cross validation procedure, $\ldots$)

We used 10 fold crossvalidation to find optimal hyperparameters $C$ and $\gamma$,
where $C$ is the maximum slack and $\gamma$ the width of the gaussian kernel.

\section{Lessons Learned}
%What other algorithms, tools or methods did you try out that didn't work well?
%Why do you think they performed worse than what you used for your final submission?

Additionally to the solution described above we tried using a majority voting
system, where we used several different additional classification methods.
The majority voting is not working that great because we don't have enough diversity in the classifiers so trying to boost doesn't help.

\end{document}
