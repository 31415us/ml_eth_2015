\documentclass[a4paper, 11pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[pdftex]{hyperref}
\usepackage{cite}

% Lengths and indenting
\setlength{\textwidth}{16.5cm}
\setlength{\marginparwidth}{1.5cm}
\setlength{\parindent}{0cm}
\setlength{\parskip}{0.15cm}
\setlength{\textheight}{22cm}
\setlength{\oddsidemargin}{0cm}
\setlength{\evensidemargin}{\oddsidemargin}
\setlength{\topmargin}{0cm}
\setlength{\headheight}{0cm}
\setlength{\headsep}{0cm}

\renewcommand{\familydefault}{\sfdefault}

\title{Machine Learning 2015: Project 3 - RCC Classification Report}
\author{ivankaya@student.ethz.ch\\vlucas@student.ethz.ch\\ piusv@student.ethz.ch\\}
\date{\today}

\begin{document}
\maketitle

\section*{Experimental Protocol}
%Suppose that someone wants to reproduce your results. Briefly describe the steps used to obtain the
%predictions starting from the raw data set downloaded from the project website. Use the following
%sections to explain your methodology. Feel free to add graphs or screenshots if you think it's
%necessary. The report should contain a maximum of 2 pages.

\section{Tools}
%Which tools and libraries have you used (e.g. Matlab, Python with scikit-learn, Java with Weka,
%SPSS, language x with library y, $\ldots$). If you have source-code (Matlab scripts, Python scripts, Java source folder, \dots),
%make sure to submit it on the project website together with this report. If you only used
%command-line or GUI-tools describe what you did.

We used $\mathbf{Matlab}$ for this project, in particular the \textit{Classification Learner}
GUI application from $\mathbf{Matlab}$'s \textit{Statistics and Machine Learning Toolbox}
to train the final classifier and the $extractLBPFeatures$ and $regionprops$ functions
to extract additional features. Additionally we used an implementation of the 
\textit{Freeman Chain Code} written by \textit{Alessandro Mannini}.

\section{Algorithm}
%Describe the algorithm you used for regression (e.g. ordinary least squares, ridge regression, $\ldots$)

We train a SVM with a linear kernel on the normalized features described below.
The $KernelScale$ parameter is set to $auto$ and we use the default $BoxConstraint$
of $1$. To prevent overfitting we use $10$-fold cross validation.

We used the \textit{Classification Learner} GUI application from $\mathbf{Matlab}$'s
\textit{Statistics and Machine Learning Toolbox} to train the SVM.


\section{Features}
%Did you construct any new features? What feature transforms did you use?

Based on~\cite{SchuefflerDAGM2010} and~\cite{schueffler2011} we extracted
the following sets of features:

\begin{itemize}
    \item \textbf{PHOG}: pyramid histograms of oriented gradients. These were
        already provided in the competition data.
    \item \textbf{SIG}: histogram of a 1D representation of a 2D boundary; already
        provided in the competition data.
    \item \textbf{COLOR}: a collection of color features extracted from the image.
        It contains 32 bin histograms of grayscale values of foreground and background and
        32 bin histograms of grayscale, red, green and blue channels of the whole image.
    \item \textbf{FCC}: freeman chain code of the nucleus border. We used the 
        $chaincode$ function written by \textit{Alessandro Mannini}.
    \item \textbf{LBP}: local binary pattern features where extracted with the
        $extractLBPFeatures$ provided by $\mathbf{Matlab}$. We used a cell size
        of $32 \times 32$.
    \item \textbf{PROPS}: additional shape information provided by $\mathbf{Matlab}$'s
        $regionprops$ function. We used: $Area$, $MajorAxisLength$, $MinorAxisLength$,
        $Eccentricity$, $EquivDiameter$, $Solidity$, $Extent$, $MeanIntensity$,
        $MinIntensity$ and $MaxIntensity$.
\end{itemize}

For our final results the \textbf{LBP} features were omitted since they lead
to worse classification results.

%\section{Parameters}
%How did you find the parameters of your model? (What parameters have you searched over, cross validation procedure, $\ldots$)

%\section{Lessons Learned}
%What other algorithms, tools or methods did you try out that didn't work well?
%Why do you think they performed worse than what you used for your final submission?

\bibliography{refs}{}
\bibliographystyle{plain}

\end{document}
